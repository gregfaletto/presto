fractions(1/3 - (8/15)^2)
package_version("testthat")
library(testthat)
package_version("testthat")
packageVersion("testthat")
remotes::install_github("jacobbien/litr-project", subdir = "litr")
rm(list=ls())
rmarkdown::draft("create-rhello.Rmd", template = "make-an-r-package", package = "litr")
rmarkdown::draft("create-rhello.Rmd", template = "make-an-r-package", package = "litr")
?case_when
library(tidyverse)
p <- c(4/16, 3/16, 2/16, 1/16, 3/16, 2/16, 1/16)
sum(p)
x <- c(0:3, -1:-3)
x
x %*% p
(x - 0)^2 %*% p
sqrt((x - 0)^2 %*% p)
2.5*16
500*1/2400 + 4*4/2400 + 10*10/2400
library(MASS)
fractions(500*1/2400 + 4*4/2400 + 10*10/2400)
77*8
x <- c(500, 4, 10, 0)
p <- c(1/2400, 4/2400, 10/2400, 2385/2400)
sum(p)
(x - 77/300)^2 %*% p
sqrt((x - 77/300)^2 %*% p)
x %*% p
77/300*5
x <- c(-1000, 0, 1000, 2000, 3000)
p <- c(0.13, 0.15, .24, 0.35, 0.13)
x %*% p
sum(p)
(1 - .45)^10
1 - (1 - .45)^10 - 10*.45*(1 - .45)^9
?binomcdf
?rbinom
pbinom(q=5, size=10, prob=0.45)
pbinom(q=0, size=10, prob=0.45)
pbinom(q=1, size=10, prob=0.45)
(1 - .45)^10 + 10*.45*(1 - .45)^9
dbinom(x=3, size=5, prob=0.25)
qnorm(p=0.7, mean=125, sd=6.5)
1 - .7^5 - 5*.3*.7^4
?rgeom
(1 - .19)^4*.19
1/.19
1 - pgeom(10, .19)
4*.6^3*.4 + .6^4
15*.6
sqrt(15*.6*.4)
5400+3070+2200-1720
5400+3070+2200-1720-6033
81346 - 75323
564-69
library(cssr)
data <- genClusteredData(n = 200, # Sample size
p = 100, # Number of features
cluster_size = 10, # Number of features in a cluster correlated with a latent variable
k_unclustered = 10, # Number of unclustered features that influence y
snr = 3 # Signal-to-noise ratio in the response y generated from the data.
)
X <- data$X
y <- data$y
output <- cssSelect(X, y)
rm(list=ls())
data <- genClusteredData(n = 80, # Sample size
p = 40, # Number of features
cluster_size = 10, # Number of features in a cluster correlated with a latent variable
k_unclustered = 10, # Number of unclustered features that influence y
snr = 3 # Signal-to-noise ratio in the response y generated from the data.
)
X <- data$X
y <- data$y
output <- cssSelect(X, y)
output <- cssSelect(X, y)
output$selected_feats
clus_output <- cssSelect(X, y, clusters=list("Z_cluster"=1:10))
clus_output <- cssSelect(X, y, clusters=list("Z_cluster"=1:10))
clus_output$selected_feats
clus_output$selected_clusts
clusters <- list("Z_clust"=1:10, 50:55)
# Wrapper functions (easy!)
n_test <- 50
n <- 200
p <- 100
testx <- matrix(rnorm(n_test*p), nrow=n_test, ncol=p)
cssPredict(X, y, testx, clusters)
clusters <- list("Z_clust"=1:10, 36:40)
# Wrapper functions (easy!)
n_test <- 50
n <- 80
p <- 40
testx <- matrix(rnorm(n_test*p), nrow=n_test, ncol=p)
# cssPredict(X, y, testx, clusters)
cssPredict(X, y, testx, clusters)
n_test <- 50
n <- 200
p <- 40
testx <- matrix(rnorm(n_test*p), nrow=n_test, ncol=p)
cssPredict(X, y, testx, clusters)
inds <- 1:round(n/2)
lambda <- getLassoLambda(X[setdiff(1:n, inds), ], y[setdiff(1:n, inds)])
lambda <- getLassoLambda(X, y)
lambda
results <- css(X=X, y=y, lambda=lambda
, clusters=clusters
# , clusters=list()
# , clusters=1:10
# , sampling.type = "SS"
# B = 100,
# , prop_feats_remove = .5
, train_inds = inds
)
inds <- 1:round(n/2)
results <- css(X=X, y=y, lambda=lambda
, clusters=clusters
# , clusters=list()
# , clusters=1:10
# , sampling.type = "SS"
# B = 100,
# , prop_feats_remove = .5
, train_inds = inds
)
nrow(X)
n
inds <- 1:40
results <- css(X=X, y=y, lambda=lambda
, clusters=clusters
# , clusters=list()
# , clusters=1:10
# , sampling.type = "SS"
# B = 100,
# , prop_feats_remove = .5
, train_inds = inds
)
str(results)
predictions <- results |> getCssPreds(testX = testx, weighting="sparse",
cutoff=0.3
, min_num_clusts=1
, max_num_clusts=3
)
predictions
train_x <- matrix(rnorm(n_test*p), nrow=n_test, ncol=p)
train_y <- rnorm(n_test)
preds2 <- results |> getCssPreds(testX = testx, weighting=w,
cutoff=c, min_num_clusts=1, max_num_clusts=3,
trainX=train_x
, trainY=train_y
)
preds2 <- results |> getCssPreds(testX = testx, weighting="sparse",
cutoff=0.3, min_num_clusts=1, max_num_clusts=3,
trainX=train_x
, trainY=train_y)
preds2
selections <- results |> getCssSelections(weighting=w, cutoff=c
# , min_num_clusts=1
# , max_num_clusts=3
)
selections <- results |> getCssSelections(weighting="sparse", cutoff=0.3
# , min_num_clusts=1
# , max_num_clusts=3
)
str(selections)
selections$selected_clusts
selections$selected_feats
results |> print.cssr(cutoff=c, min_num_clusts=1, max_num_clusts=3)
print(results)
print(results, cutoff=0.3, max_num_clusts=5)
x_design <- results |> getCssDesign(testx, weighting=w, cutoff=c, min_num_clusts=1, max_num_clusts=3)
x_design <- results |> getCssDesign(testx, weighting="weighted_avg", cutoff=0.3,
min_num_clusts=1, max_num_clusts=3)
str(x_design)
rm(list=ls())
data <- genClusteredData(n = 80, # Sample size
p = 40, # Number of features
cluster_size = 10, # Number of features in a cluster correlated with a latent variable
k_unclustered = 10, # Number of unclustered features that influence y
snr = 3 # Signal-to-noise ratio in the response y generated from the data.
)
X <- data$X
y <- data$y
output <- cssSelect(X, y)
output$selected_feats
library(cssr)
data <- genClusteredData(n = 80, # Sample size
p = 40, # Number of features
cluster_size = 10, # Number of features in a cluster correlated with a latent variable
k_unclustered = 10, # Number of unclustered features that influence y
snr = 3 # Signal-to-noise ratio in the response y generated from the data.
)
X <- data$X
y <- data$y
output <- cssSelect(X, y)
output$selected_feats
clus_output <- cssSelect(X, y, clusters=list("Z_cluster"=1:10))
clus_output$selected_feats
clus_output$selected_clusts
clusters <- list("Z_clust"=1:10, 36:40)
# Wrapper functions (easy!)
n_test <- 50
n <- 80
p <- 40
testx <- matrix(rnorm(n_test*p), nrow=n_test, ncol=p)
cssPredict(X, y, testx, clusters)
# Get a good lambda
lambda <- getLassoLambda(X, y)
# clusters <- list(1:10, 46:40)
# clusters <- 1:10
inds <- 1:40
results <- css(X=X, y=y, lambda=lambda
, clusters=clusters
# , clusters=list()
# , clusters=1:10
# , sampling.type = "SS"
# B = 100,
# , prop_feats_remove = .5
, train_inds = inds
)
str(results)
predictions <- results |> getCssPreds(testX = testx, weighting="sparse",
cutoff=0.3
, min_num_clusts=1
, max_num_clusts=3
)
predictions
train_x <- matrix(rnorm(n_test*p), nrow=n_test, ncol=p)
train_y <- rnorm(n_test)
preds2 <- results |> getCssPreds(testX = testx, weighting="sparse",
cutoff=0.3, min_num_clusts=1, max_num_clusts=3,
trainX=train_x
, trainY=train_y)
preds2
selections <- results |> getCssSelections(weighting="sparse", cutoff=0.3
# , min_num_clusts=1
# , max_num_clusts=3
)
str(selections)
selections$selected_clusts
selections$selected_feats
print(results, cutoff=0.3, max_num_clusts=5)
x_design <- results |> getCssDesign(testx, weighting="weighted_avg", cutoff=0.3,
min_num_clusts=1, max_num_clusts=3)
str(x_design)
?rowMeans
x_design
rowMeans(x_design)
str(x_design)
str(rowMeans(x_design))
?setdiff
remotes::install_github("jacobbien/litr-project", subdir = "litr",force=TRUE)
4*81
2*3^4
162*2
1750/5000
runif(1)
runif(1)
outer(rep(2, 5), rep(2, 5))
T <- 5
omega <- function(s, c){
return(diag(rep(s, T)) + matrix(rep(c, T*T), T, T))
}
omega(5, 2)
omega_inv <- function(s, c){
return(1/s*(diag(rep(1, T)) - matrix(-c/(s + T*c), T, T)))
}
omega_inv(5, 2)
omega(5, 2) %*% omega_inv(5, 2)
omega_inv <- function(s, c){
return(1/s*(- matrix(-c/(s + T*c), T, T)))
}
omega_inv(5, 2)
omega <- function(s, c){
return(diag(rep(s, T)) + matrix(rep(c, T*T), T, T))
}
omega_inv <- function(s, c){
return(1/s*(diag(rep(1, T)) - matrix(-c/(s + T*c), T, T)) )
}
omega(5, 2)
omega_inv(5,2)
diag(rep(1, T)) - matrix(-c/(s + T*c), T, T))
diag(rep(1, T)) - matrix(-c/(s + T*c), T, T)
c <- 2
5 <- s
s <- 5
diag(rep(1, T)) - matrix(-c/(s + T*c), T, T)
omega <- function(s, c){
return(diag(rep(s, T)) + matrix(rep(c, T*T), T, T))
}
omega_inv <- function(s, c){
ret <- diag(rep(1, T)) - matrix(-c/(s + T*c), T, T)
return(1/s*ret)
}
omega_inv(5, 2)
omega_inv <- function(s, c){
ret <- diag(rep(1, T)) - matrix(-c/(s + T*c), T, T)
print("intermediate:")
print(ret)
return(1/s*ret)
}
omega_inv(5, 2)
omega_inv <- function(s, c){
ret <- diag(rep(1, T)) - matrix(-c/(s + T*c), T, T)
return(1/s*ret)
}
omega(5, 2) %*% omega_inv(5, 2)
omega_inv <- function(s, c){
ret <- diag(rep(1, T)) - matrix(-s*c/(1 + T*c), T, T)
return(1/s*ret)
}
omega(5, 2) %*% omega_inv(5, 2)
omega_inv <- function(s, c){
ret <- diag(rep(1, T)) - matrix(-c/(s + T*c), T, T)
return(1/s*ret)
}
omega(5, 2) %*% omega_inv(5, 2)
outer(rep(2, 5), rep(2, 5))
rep(2, 5) %*% rep(2, 5)
omega_inv <- function(s, c){
ret <- diag(rep(1, T)) - matrix(c/(s + T*c), T, T)
return(1/s*ret)
}
omega(5, 2) %*% omega_inv(5, 2)
omega(5, 8) %*% omega_inv(5, 8)
1980.77*2
420/12
69/12
2/3*sqrt(2*.981)*.25 - .25
1/1.7*sqrt(2*.981)*.25 - .25
2/3*sqrt(2*9.81)*.25 - .25
553019/60/60/24
1 + 3.75
6.25v - (1 + 3.75)
6.25 - (1 + 3.75)
6.25 - (.5 + 3.75)
4.5 + 4.25 + 6.25
.5*-99 _ 1644
.5*-99 + 1644
.5*-75 + 2793
2755.5/60/60
1594.5/60/60
4*exp(5)
2*exp(5 + log(2))
2.5*215
8*45+118
2.5*210
library(tidyverse)
library(epipredict)
jhu <- case_death_rate_subset
jhu
canned <- arx_forecaster(epi_data=jhu, outcome="death_rate", predictors=c("case_rate", "death_rate"))
str(canned)
summary(canned)
canned
n <- 100
x <- rnorm(100)
y <- 0.01*x + rnorm(100, sd=sqrt(5))
df <- data.frame(x=x, y=y)
ggplot(df, aes(x=x, y=y)) + geom_point()
n <- 100
x <- rnorm(100)
y <- 0.01*x + rnorm(100, sd=sqrt(2))
df <- data.frame(x=x, y=y)
ggplot(df, aes(x=x, y=y)) + geom_point()
n <- 100
x <- rnorm(100)
y <- 0.1*x + rnorm(100, sd=sqrt(2))
df <- data.frame(x=x, y=y)
ggplot(df, aes(x=x, y=y)) + geom_point()
setwd("/Users/gregfaletto/Documents/GitHub/presto")
source("diabetes.R")
plot_eval_by(sim, "cal_osce_gen_data_app", varying = "age_cutoff") +
xlab("Age cutoff") + ggtitle(NULL) + ylab("Estimated Rare Probability MSE")
tabulate_eval(sim, "cal_osce_gen_data_app", se_format="None",
format_args=list(digits=3))
save_simulation(sim)
?PreDiabetes
144800*8
144800*.8
A <- matrix(c(3, 2, 2, 2), 2, 2)
A
B <- matrix(c(2, 1, 1, 2), 2, 2)
B
eigen(A)
eigen(B)
eigen(A - B)
A - B
A
B
setwd("~/My Drive/Data Science/LaTeX/dissertation2")
getwd()
.8*150
1.2*150
30/170
10.38/1.53
8.86/5.16
2.57/1.62
2.59/1.1
10.4/3.15
8.84/7.56
2.56/2.44
2.59/1.75
.527/.044
2.5/.094
1.03/.033
16.54/.393
.53/.12
2.5/.248
1.04/.093
16.65/1.08
2593.57/7
410/22/9
681/6
5120/2880
5120/2
2592/1296
5120/2592
2592/72
100-78.4
100-20.3
install.packages("simulator")
2+2
851.7*2
851.70 +425/2
221/12
29.44/7.8
360/14
library(ordinal)
data(soup)
str(soup)
library(MASS)
model_soup <- polr(SURENESS ~ PROD + DAY + SOUPTYPE + SOUPFREQ + COLD + EASY +
GENDER + AGEGROUP + LOCATION, data=soup)
ages_vector <- c(“18-24", “18-24", “45-54", "25-34", “35-44“)
ages_vector <- c("18-24", "18-24", "45-54", "25-34", “35-44“)
ages_vector <- c("18-24", "18-24", "45-54", "25-34", "35-44")
ages_vector
factor_ages_vector <- factor(ages_vector, order = TRUE, levels = c("18-24", "25-34", "35-44","45-54"))
factor_ages_vector
model_soup <- polr(SURENESS ~ PROD + DAY + SOUPTYPE + SOUPFREQ + COLD + EASY + GENDER + AGEGROUP + LOCATION, data=soup)
model_soup
summary(soup$SURENESS)/length(soup$SURENESS)
predict(model_soup, data=soup, type="probs")
# Example of creating an ordinal categorical variable from scratch
# Categorical vector of age groupings
ages <- c(">35", "<25", ">35", "25-29", "30-35")
ages
# Specify that they are ordinal variables with the given levels
factor_ages <- factor(ages, order = TRUE,
levels = c("<25", "25-29", "30-35",">35"))
factor_ages
# Run this line of code if you haven't already installed the ordinal package
# install.packages(“ordinal”)
library(ordinal)
# Load the soup data set
data(soup)
# Take a look at the data
str(soup)
# Get the proportion of observations that lie in each class
summary(soup$SURENESS)/length(soup$SURENESS)
# Train proportional odds model
library(MASS)
model_soup <- polr(SURENESS ~ PROD + DAY + SOUPTYPE + SOUPFREQ +
COLD + EASY + GENDER + AGEGROUP + LOCATION,
data=soup)
model_soup
# Get predicted probabilities of lying in each class for each
# observation in the data set
predict(model_soup, data=soup, type="probs")
setwd("~/Documents/GitHub/presto")
source("presto_func.R")
source("example_code.R")
source("example_code.R")
source("example_code.R")
source("example_code.R")
setwd("~/Documents/GitHub/presto")
source("example_code.R")
?model.matrix
source("example_code.R")
str(dat)
colnames(dat)
source("example_code.R")
str(dat)
colnames(dat)
source("example_code.R")
source("example_code.R")
K
K <- length(unique(soup$SURENESS))
K
print("Done! Fitting model...")
# Fit model on rest of data using selected lambda and get parameter estimates
t0 <- Sys.time()
ret_list <- presto(X, y, lambdaVals=lambda_star, K=K)
print(Sys.time() - t0)
alpha_hat <- ret_list$alpha_hat
Beta_hat <- ret_list$Beta_hat
print("Done! alpha_hat:")
print(alpha_hat)
print("Beta_hat:")
print(Beta_hat)
source("example_code.R")
source("example_code.R")
source("example_code.R")
source("example_code.R")
names(ret)
names(res)
str(y)
type(y)
class(y)
source("example_code.R")
source("example_code.R")
